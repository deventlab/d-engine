# d-engine v0.2.0 Performance Benchmark Report

**Date:** December 9, 2025  
**Hardware:** Apple Mac mini M2 (8-core, 16GB) - Single machine, 3-node cluster

---

## Performance Comparison: 2025-12-09 vs 2025-12-05 Baseline

> **Context**: This report measures performance after implementing current_leader_id lifecycle (#201, #203).

| Test                       | 2025-12-09    | 2025-12-05 (baseline) | Change       |
| -------------------------- | ------------- | --------------------- | ------------ |
| **Single client write**    | 550 ops/s     | 553 ops/s             | ✅ -0.5%     |
| **High concurrency write** | 62,913 ops/s  | 67,127 ops/s          | ⚠️ **-6.3%** |
| **Linearizable read**      | 12,286 ops/s  | 11,948 ops/s          | ✅ **+2.8%** |
| **LeaseRead**              | 99,418 ops/s  | 92,239 ops/s          | ✅ **+7.8%** |
| **EventualConsistency**    | 126,095 ops/s | 115,471 ops/s         | ✅ **+9.2%** |
| **Hot-key (key-space=10)** | 12,245 ops/s  | 11,683 ops/s          | ✅ **+4.8%** |

### Latency Comparison (p99)

| Test                   | 2025-12-09 p99 | 2025-12-05 p99 | Change      |
| ---------------------- | -------------- | -------------- | ----------- |
| Single client write    | 3.40 ms        | 2.26 ms        | ⚠️ +50%     |
| High concurrency write | 6.57 ms        | 5.92 ms        | ⚠️ +11%     |
| Linearizable read      | 23.01 ms       | 25.01 ms       | ✅ **-8%**  |
| LeaseRead              | 4.65 ms        | 4.74 ms        | ✅ **-2%**  |
| EventualConsistency    | 7.91 ms        | 8.67 ms        | ✅ **-9%**  |
| Hot-key                | 21.82 ms       | 26.61 ms       | ✅ **-18%** |

---

## Summary

**Read performance improved significantly (+2.8% to +9.2%) with NO regression from #201/#203 changes.**

Key findings:

- **Read throughput improved by 2.8-9.2%** across all consistency levels
- **Read latency (p99) improved by 2-18%** for linearizable, lease-based, and eventual reads
- Write throughput regression (-6.3%) requires further investigation (may be environment-related)
- Single client write p99 spike (3.40ms) caused by 2 timeout errors during cluster warm-up

---

## Recent Changes Impact Analysis

| Feature                    | Ticket | Impact on Performance                   |
| -------------------------- | ------ | --------------------------------------- |
| current_leader_id in proto | #201   | ✅ No regression on hot path            |
| Lifecycle integration test | #203   | ✅ Test coverage only, no runtime cost  |
| Embedded test fixes        | #203   | ✅ Test infrastructure, no runtime cost |

### Observations

1. **#201 (current_leader_id) has NO performance impact**
   - Metadata API calls are on cold path only (ClusterConf events, join responses)
   - Hot path (AppendEntries, client reads/writes) unchanged
   - Read performance actually improved, likely due to system variance

2. **Write regression (-6.3%) root cause unclear**
   - Not correlated with code changes (metadata API not in write path)
   - May be environmental factors (system load, network jitter)
   - Recommend re-running on clean environment

3. **Single client timeout errors**
   - 2 errors during initial requests: `DeadlineExceeded`, `ConnectionTimeout`
   - Max latency spike to 344ms (vs typical <100ms)
   - Root cause: Cluster not fully stabilized after startup
   - **Recommendation**: Add 5-second warm-up period before benchmarking

---

## Test Commands

```bash
# 1. Single client write (baseline: 553 ops/s)
./target/release/d-engine-bench \
    --endpoints http://127.0.0.1:9081 --endpoints http://127.0.0.1:9082 --endpoints http://127.0.0.1:9083 \
    --conns 1 --clients 1 --sequential-keys --total 100000 \
    --key-size 8 --value-size 256 put

# 2. High concurrency write (baseline: 67,127 ops/s)
./target/release/d-engine-bench \
    --endpoints http://127.0.0.1:9081 --endpoints http://127.0.0.1:9082 --endpoints http://127.0.0.1:9083 \
    --conns 200 --clients 1000 --sequential-keys --total 100000 \
    --key-size 8 --value-size 256 put

# 3. Linearizable read (baseline: 11,948 ops/s)
./target/release/d-engine-bench \
    --endpoints http://127.0.0.1:9081 --endpoints http://127.0.0.1:9082 --endpoints http://127.0.0.1:9083 \
    --conns 200 --clients 1000 --sequential-keys --total 200000 \
    --key-size 8 range --consistency l

# 4. Lease-based read (baseline: 92,239 ops/s)
./target/release/d-engine-bench \
    --endpoints http://127.0.0.1:9081 --endpoints http://127.0.0.1:9082 --endpoints http://127.0.0.1:9083 \
    --conns 200 --clients 1000 --sequential-keys --total 200000 \
    --key-size 8 range --consistency s

# 5. Eventual consistency read (baseline: 115,471 ops/s)
./target/release/d-engine-bench \
    --endpoints http://127.0.0.1:9081 --endpoints http://127.0.0.1:9082 --endpoints http://127.0.0.1:9083 \
    --conns 200 --clients 1000 --sequential-keys --total 200000 \
    --key-size 8 range --consistency e

# 6. Hot-key test with --key-space (baseline: 11,683 ops/s)
./target/release/d-engine-bench \
    --endpoints http://127.0.0.1:9081 --endpoints http://127.0.0.1:9082 --endpoints http://127.0.0.1:9083 \
    --conns 200 --clients 1000 --total 200000 --key-size 8 \
    --key-space 10 \
    range --consistency l
```

---

## Detailed Results

### 1. Single Client Write
```
Total time:     181.73 s
Requests:       100000
Throughput:     550.27 ops/sec

Latency distribution (μs):
 Avg    1810.89
 Min    152
 Max    344063    ⚠️ Anomaly spike
 p50    1780
 p90    2109
 p99    3403
 p99.9  11687

Errors: 2 timeouts (DeadlineExceeded, ConnectionTimeout)
```

### 2. High Concurrency Write
```
Total time:     1.61 s
Requests:       100999
Throughput:     62913.12 ops/sec

Latency distribution (μs):
 Avg    3175.95
 Min    525
 Max    12103
 p50    2975
 p90    4563
 p99    6567
 p99.9  9815
```

### 3. Linearizable Read
```
Total time:     16.36 s
Requests:       200999
Throughput:     12286.41 ops/sec

Latency distribution (μs):
 Avg    16268.46
 Min    889
 Max    29103
 p50    16255
 p90    16799
 p99    23007
 p99.9  26047
```

### 4. LeaseRead
```
Total time:     2.02 s
Requests:       200999
Throughput:     99418.19 ops/sec

Latency distribution (μs):
 Avg    2009.39
 Min    57
 Max    24175
 p50    1873
 p90    3025
 p99    4647
 p99.9  16039
```

### 5. EventualConsistency
```
Total time:     1.59 s
Requests:       200999
Throughput:     126095.12 ops/sec

Latency distribution (μs):
 Avg    1583.17
 Min    34
 Max    28063
 p50    1024
 p90    3821
 p99    7911
 p99.9  12599
```

### 6. Hot-Key (key-space=10)
```
Total time:     16.41 s
Requests:       200999
Throughput:     12245.26 ops/sec

Latency distribution (μs):
 Avg    16322.76
 Min    1023
 Max    29663
 p50    16287
 p90    16863
 p99    21823
 p99.9  25279
```

---

## Next Steps

1. **Investigate write regression**
   - Re-run benchmark on clean environment
   - Profile write path for any unexpected overhead
   - Verify if related to system load vs code changes

2. **Improve benchmark setup**
   - Add 5-second cluster warm-up period
   - Implement pre-benchmark health check
   - Retry failed requests to reduce noise

3. **Continuous monitoring**
   - Track performance trends across releases
   - Set up automated regression detection
   - Add performance budgets for CI/CD
